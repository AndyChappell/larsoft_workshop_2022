{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, cv2, math, numpy as np, os, time, torch, torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *\n",
    "from helpers import *\n",
    "from model_utils import *\n",
    "from training_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_grad_requirement(model, mode):\n",
    "    \"\"\"Set the parameters of a model to require gradients or not\n",
    "\n",
    "        Args:\n",
    "            model: The model whose parameter mutability should be set\n",
    "            is_required: Whether or not gradients are required\n",
    "            last_frozen_layer: The last layer that should not be tuned, if mode == 'partial'\n",
    "    \"\"\"\n",
    "    \n",
    "    is_required = True if mode.lower() == 'full' else False\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = is_required  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ca133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_reshape(model, target_size):\n",
    "    \"\"\"Reshapes the final layer of a model\n",
    "\n",
    "        Args:\n",
    "            model: The model to be reshaped\n",
    "            target_size: The number of outputs required\n",
    "    \"\"\"\n",
    "    input_size = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(input_size, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm\n",
    "\n",
    "def train_model(model, epochs, criterion, optimizer, scheduler, dataloaders, dataset_sizes, device, output_filename):\n",
    "    \"\"\"Runs the training loop for a model\n",
    "\n",
    "        Args:\n",
    "            model: The model to be trained\n",
    "            epochs: The number of epochs to train for\n",
    "            criterion: The loss function to be optimised\n",
    "            optimizer: The optimizer to use\n",
    "            scheduler: The learning rate scheduler to use\n",
    "            dataloaders: A dictionary containing the training ('train') and validation ('val') data loaders\n",
    "            dataset_sizes: The number of samples in the training ('train') and validation ('val') datasets\n",
    "            device: The device on which training should be run\n",
    "            output_filename: The output model filename\n",
    "        \n",
    "        Returns:\n",
    "            A tuple containing the best model and the metric history\n",
    "    \"\"\"\n",
    "    statistics = {\n",
    "        'train': { 'loss': [], 'accuracy': [], 'f1': [] },\n",
    "        'val': { 'loss': [], 'accuracy': [], 'f1': [] },\n",
    "        'test': { 'loss': [], 'accuracy': [], 'f1': [] }\n",
    "    }\n",
    "    best_stat = 0.0\n",
    "    best_epoch = 0\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    epoch = 1\n",
    "    learning = True\n",
    "    while learning:\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            predictions = [None] * len(dataloaders[phase])\n",
    "            truths = [None] * len(dataloaders[phase])\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for b, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    predictions[b] = preds\n",
    "                    truths[b] = labels.data\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "            update_statistics(statistics[phase], running_loss / dataset_sizes[phase], predictions, truths)\n",
    "            print_statistics(statistics, phase, epoch)\n",
    "\n",
    "            if phase == 'val' and statistics['val']['f1'][-1] > best_stat:\n",
    "                best_stat = statistics['val']['f1'][-1]\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "                best_epoch = epoch\n",
    "                \n",
    "            if phase == 'val':\n",
    "                last_lr = optimizer.param_groups[0]['lr']\n",
    "                scheduler.step(running_loss / dataset_sizes[phase])\n",
    "                if optimizer.param_groups[0]['lr'] != last_lr:\n",
    "                    model.load_state_dict(best_model)\n",
    "\n",
    "        print()\n",
    "        epoch += 1\n",
    "        if epoch > epochs:\n",
    "            learning = False\n",
    "\n",
    "    print('Best validation F1 score: {:4f}'.format(best_stat))\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "    save_model(model, f\"{output_filename}\")\n",
    "\n",
    "    return model, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5b697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(baseline_filename, epochs, weights, output_filename, pretrained=True, finetune='full', in_classes=2, out_classes=2):\n",
    "    \"\"\"Trains the classifier layer of a network.\n",
    "    \n",
    "        Args:\n",
    "            baseline_filename: The name of the file containing pretrained weights\n",
    "            epochs: The number of epochs to train for\n",
    "            weights: The class weights to use for loss function normalisation\n",
    "            output_filename: The output model filename\n",
    "            pretrained: Whether a pretrained model should be loaded\n",
    "            finetune: The type of finetuning to apply if using a pretrained model ('full', 'classifier', 'partial')\n",
    "            num_classes: The number of classes in the new output layer\n",
    "    \n",
    "        Returns:\n",
    "            The best trained model based on f1 score\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = tv.models.resnet18(pretrained=pretrained)\n",
    "    mode = 'full' if not pretrained else finetune.lower()\n",
    "    set_model_grad_requirement(model, mode)\n",
    "    model_reshape(model, in_classes)\n",
    "    model.load_state_dict(torch.load(baseline_filename, map_location=device))\n",
    "    model_reshape(model, out_classes)\n",
    "    print_parameters(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    if not pretrained:\n",
    "        reinit_conv_layers(model)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(torch.as_tensor(weights, device=device, dtype=torch.float))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, threshold=1e-4)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    model, epoch_statistics = train_model(model, epochs, criterion, optimizer, scheduler, dataloaders, dataset_sizes, device,\n",
    "                                          output_filename)\n",
    "    t1 = time.perf_counter()\n",
    "    print(f\"Network {iter} trained in {t1 - t0} s\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695fd57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 4\n",
    "\n",
    "transform = get_resnet_transforms()\n",
    "training_set, validation_set = make_datasets(f\"images\", transform, valid_size=10000, train_size=8000)\n",
    "dataloaders, dataset_sizes, weights = prepare_dataloaders(training_set, validation_set, batch_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70daaafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(\"model_baseline.pt\", 10, weights, \"model_transfer\", pretrained=True, finetune='classifier', in_classes=2, out_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(\"model_transfer.pt\", 5, weights, \"model_final\", pretrained=True, finetune='full', in_classes=num_classes,\n",
    "              out_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d9c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
